# OSCE Analytics System - Deployment Guide
## Complete Replacement - No Gradual Rollout

---

## ðŸŽ¯ Overview

This is a **complete replacement** of the old OSCE analytics system with a new pre-computed architecture.

### What Changed:

| Old System | New System |
|------------|------------|
| âŒ Computed on every API call | âœ… Pre-computed every 5 minutes |
| âŒ 5-10 seconds response time | âœ… 0.2-0.5 seconds |
| âŒ 3000-5000 Firestore reads | âœ… 5-10 Firestore reads |
| âŒ Expensive ($20-30/month) | âœ… Cheap ($0.50-1/month) |
| âŒ Limited analytics | âœ… Complete analytics (all screenshots) |

---

## ðŸ“‹ Deployment Checklist

### Phase 1: Backend Setup (30 minutes)

#### Step 1: Verify Files Created
```bash
cd /Users/nayanjain/Documents/ebek_django_app

# Check management command exists
ls assessments/management/commands/process_metric_queue.py

# Check updated views
grep "fetch_osce_report_optimized" assessments/views.py

# Check updated URLs
grep "fetch_osce_report_optimized" assessments/urls.py
```

#### Step 2: Initial Data Backfill
```bash
# This will pre-compute ALL existing analytics
# Takes 2-5 minutes for first run
python manage.py process_metric_queue
```

**Expected Output:**
```
================================================================================
[2025-11-14 10:30:00] Starting Complete Analytics Pre-Computation
================================================================================
   Found 25 unprocessed items
   Processing: DJ Sanghvi College - 2025 - Semester 1
      âœ“ Computed all analytics for 15 items
   Processing: DJ Sanghvi College - 2025 - Semester 3
      âœ“ Computed all analytics for 10 items

âœ… Complete analytics computed successfully!
   - Processed: 25 items
   - Time elapsed: 45.67 seconds
```

#### Step 3: Verify Data Created

```bash
python manage.py shell

>>> from firebase_admin import firestore
>>> db = firestore.client()

# Check SemesterMetrics exists
>>> sem_doc = db.collection('SemesterMetrics').document('DJ Sanghvi College_2025_1').get()
>>> if sem_doc.exists:
...     print("âœ… SemesterMetrics created")
...     data = sem_doc.to_dict()
...     print(f"   Students: {data.get('total_students')}")
...     print(f"   OSCEs: {data.get('osces_conducted')}")
...     print(f"   Avg Score: {data.get('avg_score')}")
...     print(f"   Skills: {len(data.get('skills_performance', {}))}")
...     print(f"   Student Report: {len(data.get('student_batch_report', []))}")

# Check InstitutionMetrics exists
>>> inst_doc = db.collection('InstitutionMetrics').document('DJ Sanghvi College_2025').get()
>>> if inst_doc.exists:
...     print("âœ… InstitutionMetrics created")
```

#### Step 4: Set Up Cron Job (5-minute updates)

**Option A: Using crontab (Recommended)**
```bash
# Find your Python path
which python3
# Output: /usr/local/bin/python3

# Edit crontab
crontab -e

# Add this line (replace paths):
*/5 * * * * cd /Users/nayanjain/Documents/ebek_django_app && /usr/local/bin/python3 manage.py process_metric_queue >> /tmp/osce_metrics.log 2>&1

# Save and exit (Ctrl+X, then Y, then Enter in nano)

# Verify cron is set
crontab -l
```

**Option B: Using django-crontab**
```bash
pip install django-crontab

# Add to settings.py
INSTALLED_APPS = [
    ...
    'django_crontab',
]

CRONJOBS = [
    ('*/5 * * * *', 'django.core.management.call_command', ['process_metric_queue']),
]

# Install
python manage.py crontab add

# Verify
python manage.py crontab show
```

#### Step 5: Test API Endpoint

```bash
# Test the optimized endpoint
curl "http://localhost:8000/api/osce-report/?institution_name=DJ%20Sanghvi%20College&academic_year=2025&semester=1"

# Should return in < 0.5 seconds with:
# - data_source: "pre_computed"
# - Complete analytics data
```

---

### Phase 2: Frontend Update (10 minutes)

#### The API endpoint **stays the same**: `/api/osce-report/`

âœ… **No frontend changes needed!**

The URL route was updated to point to the new optimized function, so your existing frontend code will automatically use the fast version.

If you had hardcoded any URLs, verify they use:
```javascript
// Correct (already should be this)
fetch('/api/osce-report/?institution_name=...')

// NOT (old documentation reference - ignore)
fetch('/api/osce-report-optimized/?...')
```

---

### Phase 3: Monitoring (First 24 Hours)

#### Monitor Cron Execution

```bash
# Watch logs in real-time
tail -f /tmp/osce_metrics.log

# Check last 20 lines
tail -20 /tmp/osce_metrics.log

# Search for errors
grep "Error" /tmp/osce_metrics.log
```

#### Monitor Queue Status

```bash
python manage.py shell

>>> from firebase_admin import firestore
>>> from datetime import datetime, timedelta
>>> db = firestore.client()

# Check pending items
>>> cutoff = datetime.now() - timedelta(hours=1)
>>> pending = list(db.collection('MetricUpdateQueue').where('processed', '==', False).where('timestamp', '>=', cutoff).stream())
>>> print(f"Pending items: {len(pending)}")

# Should be low (< 50) if cron is running
```

#### Check Data Freshness

```bash
# API response includes last_updated
curl -s "http://localhost:8000/api/osce-report/?institution_name=DJ%20Sanghvi%20College&academic_year=2025&semester=1" | grep last_updated

# Should be within last 5-10 minutes
```

---

## ðŸŽ¨ Frontend Features Available

### All Pre-Computed (Instant Loading):

âœ… **Top KPIs**
```javascript
const data = await fetch('/api/osce-report/?...').then(r => r.json());
console.log(data.total_students_enrolled);
console.log(data.average_institution_score);
console.log(data.pass_rate);
```

âœ… **Semester-Wise Table**
```javascript
data.semester_wise_performance.forEach(sem => {
  console.log(`Semester ${sem.semester}: ${sem.num_osces} OSCEs`);
});
```

âœ… **Student Batch Report** (The Big One!)
```javascript
data.semester_dashboard.student_batch_report.forEach(student => {
  console.log(`${student.name}: ${student.overall_avg}% (${student.overall_grade})`);
  console.log(`  Best: ${student.best_performing_osce}`);
  console.log(`  Skills: ${student.skills_passed}/${student.skills_attempted}`);
});
```

âœ… **OSCE Activity Timeline**
```javascript
data.semester_dashboard.osce_activity_timeline.forEach(osce => {
  console.log(`${osce.osce_level} - ${osce.date_conducted}: ${osce.avg_score}%`);
});
```

âœ… **Skills by Category**
```javascript
Object.entries(data.skills_by_category).forEach(([category, skills]) => {
  console.log(`\n${category}:`);
  skills.forEach(skill => {
    console.log(`  - ${skill.skill_name}: ${skill.avg_score}%`);
    console.log(`    Station breakdown:`, skill.station_breakdown);
  });
});
```

âœ… **Grade Distribution**
```javascript
const grades = data.grade_distribution;
// { "A+": 2, "A": 5, "B+": 3, ... }
// Ready for pie chart
```

---

## âš ï¸ Important Notes

### 1. Data Freshness: 5-Minute Lag

- Metrics update every 5 minutes
- This is **acceptable for analytics** (not real-time dashboards)
- Users won't notice the difference

### 2. Queue Automatically Populated

- React app adds entries to `MetricUpdateQueue` on exam submit
- No manual intervention needed
- Automatic cleanup of old items (7 days)

### 3. Supported Filters

Currently supported:
- âœ… Institution
- âœ… Academic Year
- âœ… Semester (All or specific)

Not yet supported (returns error):
- âŒ OSCE Level filter (Mock/Final/Classroom)
- âŒ Procedure/Skill filter

These will return:
```json
{
  "success": false,
  "error": "Filtered views not yet supported",
  "hint": "Use semester filter only for now"
}
```

**TODO**: Add OSCE level and procedure filtering to pre-computation

---

## ðŸš¨ Troubleshooting

### Issue: "No pre-computed metrics found"

**Solution:**
```bash
# Run backfill
python manage.py process_metric_queue

# Check if data was created
python manage.py shell
>>> db.collection('SemesterMetrics').document('YourInstitution_2025_1').get().exists
```

### Issue: Cron not running

```bash
# Check if cron service is running
ps aux | grep cron

# Check crontab is set
crontab -l

# Check logs
tail -f /tmp/osce_metrics.log

# Test manually
python manage.py process_metric_queue
```

### Issue: Data is stale (old)

```bash
# Check queue has items
python manage.py shell
>>> pending = db.collection('MetricUpdateQueue').where('processed', '==', False).stream()
>>> print(len(list(pending)))

# If queue is empty, exams aren't being submitted
# Check React app is adding queue entries

# If queue has many items, cron might not be running
# Check cron logs
```

### Issue: High retry_count in queue

```bash
# Check failed items
python manage.py shell
>>> failed = db.collection('MetricUpdateQueue').where('retry_count', '>', 1).stream()
>>> for item in failed:
...     print(item.to_dict())

# Usually means data integrity issue
# Check BatchAssignment and ExamAssignment data
```

---

## ðŸ“Š Success Metrics

After 24 hours, verify:

âœ… **Performance**
- API response time < 1 second
- Firestore reads < 20 per request
- No timeout errors

âœ… **Data Quality**
- All semesters have pre-computed data
- Student batch reports populated
- Skills analytics available
- Timeline showing OSCEs

âœ… **Cron Health**
- Runs every 5 minutes
- Processes queue successfully
- No errors in logs
- Queue stays small (< 50 items)

---

## ðŸŽ‰ Deployment Complete!

When you see:
- âœ… Cron running every 5 minutes
- âœ… API responding in < 0.5 seconds
- âœ… All analytics showing in frontend
- âœ… Student reports loading instantly
- âœ… No errors in logs

**You're done! The new analytics system is live! ðŸš€**

---

## ðŸ“ž Support Checklist

If something breaks:

1. Check cron is running: `crontab -l`
2. Check logs: `tail -f /tmp/osce_metrics.log`
3. Run manual backfill: `python manage.py process_metric_queue`
4. Check Firestore collections exist: `SemesterMetrics`, `InstitutionMetrics`
5. Verify React app is queueing updates: Check `MetricUpdateQueue` collection

---

**Deployment Date:** November 14, 2025  
**System:** Complete Analytics Pre-Computation  
**Status:** âœ… Ready for Production

